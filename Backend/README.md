# Story Teller API

An AI-powered "Choose Your Own Adventure" story API built with FastAPI, LangChain, and Google Gemini.

## Features

- ðŸŽ­ **Interactive Stories** - Create branching narrative adventures
- ðŸ¤– **AI-Powered Generation** - Uses Google Gemini to generate story content
- ðŸŒ³ **Tree Structure** - Stories are organized as navigable decision trees
- âš¡ **Async Processing** - Background job queue for story generation
- ðŸ“Š **Full CRUD** - Complete API for stories, nodes, and jobs
- ðŸ”’ **Production Ready** - Logging, error handling, health checks

## Quick Start

### Prerequisites

- Python 3.11+
- PostgreSQL (or SQLite for development)
- Google Gemini API key

### Installation

1. **Clone and navigate to the backend:**
   ```bash
   cd Backend
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv .venv
   
   # Windows
   .venv\Scripts\activate
   
   # macOS/Linux
   source .venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -e ".[dev]"
   ```

4. **Set up environment variables:**
   ```bash
   cp .env.example .env
   # Edit .env with your settings
   ```

5. **Run database migrations:**
   ```bash
   alembic upgrade head
   ```

6. **Start the server:**
   ```bash
   uvicorn main:app --reload
   ```

7. **Open the API docs:**
   - Swagger UI: http://localhost:8000/docs
   - ReDoc: http://localhost:8000/redoc

## Configuration

Create a `.env` file with these settings:

```env
# Environment
ENVIRONMENT=development
DEBUG=True
LOG_LEVEL=INFO

# Security
SECRET_KEY=your-super-secret-key-change-in-production
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/storyteller
# Or for SQLite development:
# DATABASE_URL=sqlite:///./story_teller.db

# AI
GEMINI_API_KEY=your-gemini-api-key
```

## API Endpoints

### Stories

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/stories/` | Create a new story |
| `GET` | `/api/v1/stories/` | List all stories (paginated) |
| `GET` | `/api/v1/stories/{id}` | Get story with tree structure |
| `GET` | `/api/v1/stories/session/{session_id}` | Get story by session |
| `PATCH` | `/api/v1/stories/{id}` | Update story metadata |
| `DELETE` | `/api/v1/stories/{id}` | Delete a story |

### Story Nodes

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/stories/{id}/nodes` | Add a node to a story |
| `GET` | `/api/v1/stories/{id}/nodes` | List all nodes |
| `GET` | `/api/v1/stories/{id}/nodes/{node_id}` | Get node with children |
| `PATCH` | `/api/v1/stories/{id}/nodes/{node_id}` | Update a node |
| `DELETE` | `/api/v1/stories/{id}/nodes/{node_id}` | Delete a node |

### Jobs (AI Generation)

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/jobs/` | Start a generation job |
| `GET` | `/api/v1/jobs/` | List all jobs |
| `GET` | `/api/v1/jobs/{job_id}` | Get job details |
| `GET` | `/api/v1/jobs/{job_id}/status` | Poll job status |
| `POST` | `/api/v1/jobs/{job_id}/cancel` | Cancel a pending job |
| `DELETE` | `/api/v1/jobs/{job_id}` | Delete a completed job |

### Health

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Full health check |
| `GET` | `/health/ready` | Readiness probe |
| `GET` | `/health/live` | Liveness probe |

## Project Structure

```
Backend/
â”œâ”€â”€ alembic/                 # Database migrations
â”‚   â”œâ”€â”€ versions/            # Migration files
â”‚   â””â”€â”€ env.py               # Alembic configuration
â”œâ”€â”€ core/                    # Core business logic
â”‚   â”œâ”€â”€ config.py            # Settings management
â”‚   â”œâ”€â”€ exceptions.py        # Custom exceptions
â”‚   â”œâ”€â”€ logging.py           # Logging configuration
â”‚   â”œâ”€â”€ prompts.py           # AI prompt templates
â”‚   â””â”€â”€ story_generator.py   # AI story generation
â”œâ”€â”€ db/                      # Database layer
â”‚   â””â”€â”€ database.py          # SQLAlchemy setup
â”œâ”€â”€ models/                  # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ job.py               # Job model
â”‚   â””â”€â”€ story.py             # Story & StoryNode models
â”œâ”€â”€ routers/                 # API endpoints
â”‚   â”œâ”€â”€ jobs.py              # Job endpoints
â”‚   â””â”€â”€ story.py             # Story endpoints
â”œâ”€â”€ schema/                  # Pydantic schemas
â”‚   â”œâ”€â”€ job.py               # Job request/response schemas
â”‚   â””â”€â”€ story.py             # Story request/response schemas
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ conftest.py          # Test fixtures
â”‚   â”œâ”€â”€ test_health.py       # Health endpoint tests
â”‚   â””â”€â”€ test_stories.py      # Story endpoint tests
â”œâ”€â”€ .env                     # Environment variables (not in git)
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ alembic.ini              # Alembic configuration
â”œâ”€â”€ main.py                  # FastAPI application
â”œâ”€â”€ pyproject.toml           # Project dependencies
â””â”€â”€ README.md                # This file
```

## Development

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test file
pytest tests/test_stories.py -v
```

### Code Quality

```bash
# Format code
black .

# Lint code
ruff check .

# Type check
mypy .
```

### Database Migrations

```bash
# Create a new migration
alembic revision --autogenerate -m "Description of changes"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# View migration history
alembic history
```

## Deployment

### Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY pyproject.toml .
RUN pip install .

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Production Checklist

- [ ] Set `ENVIRONMENT=production`
- [ ] Set `DEBUG=False`
- [ ] Use a strong `SECRET_KEY`
- [ ] Configure proper `ALLOWED_ORIGINS`
- [ ] Use PostgreSQL (not SQLite)
- [ ] Run migrations with `alembic upgrade head`
- [ ] Set up proper logging aggregation
- [ ] Configure health check endpoints in load balancer

## License

MIT License - see LICENSE file for details.
